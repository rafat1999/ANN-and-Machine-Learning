# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eZrM0DFk3tnltm92Waz_1Tmzuvh6XuOV
"""

from google.colab import drive

drive.mount('/content/gdrive')

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import OneHotEncoder

dataframe = pd.read_csv('/content/gdrive/MyDrive/L-4; T-1/kidney_disease.csv')
#dataframe
dataframe = dataframe.dropna()

# load the boston dataset 
#dataframe =  pd.read_csv('SAheart.csv')
# le = LabelEncoder()
# dataframe['classification'] = le.fit_transform(dataframe['classification'])

# defining feature matrix(X) and response vector(y) 
X = dataframe.iloc[:,1:-1] # last er ta bade
y = dataframe.iloc[:,-1] #last er ta

#convert categorical to numeric
labelencoder_X=LabelEncoder()
z = X.iloc[:,5]  #0,1,2,3,4
#print(z)

X.iloc[:,5] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,6]  #0,1,2,3,4
#print(z)

X.iloc[:,6] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,7]  #0,1,2,3,4
#print(z)

X.iloc[:,7] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,8]  #0,1,2,3,4
#print(z)

X.iloc[:,8] = labelencoder_X.fit_transform(z.values.ravel())


labelencoder_X=LabelEncoder()
z = X.iloc[:,18]  #0,1,2,3,4
#print(z)

X.iloc[:,18] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,19]  #0,1,2,3,4
#print(z)

X.iloc[:,19] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,20]  #0,1,2,3,4
#print(z)

X.iloc[:,20] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,21]  #0,1,2,3,4
#rint(z)

X.iloc[:,21] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,22]  #0,1,2,3,4
#print(z)

X.iloc[:,22] = labelencoder_X.fit_transform(z.values.ravel())

labelencoder_X=LabelEncoder()
z = X.iloc[:,23]  #0,1,2,3,4
#print(z)
X.iloc[:,23] = labelencoder_X.fit_transform(z.values.ravel())

#z score normalization
scaller = StandardScaler()
X = scaller.fit_transform(X)


# encode class values as integers
encoder = LabelEncoder()
encoder.fit(y)
y = encoder.transform(y)

# splitting X and y into training and testing sets  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

from keras.utils import np_utils
# convert integers to dummy variables (i.e. one hot encoded)
y_train = np_utils.to_categorical(y_train)


#print(X_train.shape)
#print(y_train)
#print(y_test)


# define the keras model
model = Sequential()
model.add(Dense(6, input_dim=24, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(2, activation='softmax'))

# compile the keras model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


# fit the keras model on the dataset
model.fit(X_train, y_train, epochs=200, batch_size=5)

acc = model.evaluate(X_train, y_train)
print("Loss:", acc[0], " Accuracy:", acc[1])

pred = model.predict(X_test)
pred_y = pred.argmax(axis=-1)

#count_class(train_label)

#print(y_test)
#print(pred)